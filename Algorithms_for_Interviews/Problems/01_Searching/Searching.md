# Binary Search

Binary searches are a very popular search question during interviews.

Natural Divide and Conquer technique. Using the presumtion that we have a sorted list we can strategically eliminate half of the values during each operation based on evaluating the target to the current midpoint key.

Tricky to implement correctly if you're not careful about maintaining indeces.

# Hashing

Hashing is different from binary search in that the main approach is to store keys in an array of length m. And the array in which each element is the hash code generated by a hashing function. A good hash function generates a uniform distribution randomly.

There is the possibility that a hashing function will generate the same hash code given two distinct input, whcih will cause a collision in the hash table. A common approach to dealing with collisions is to maintain a linked list of keys at each location. Lookups, inserts, and deletes take $O(1+n/m)$ complexity.

If we find that the ratio $n/m$ of instances to hash indeces grows large, then we may rehash the entire table. This is an expensive operation, $\Theta(n+m)$, but is generally performed in infrequent situations, such as when the load doubles.

Inserting and deleting elements is more efficient than in binary trees, however, this requires a decenthashing function which causes few collisions. This is rarely an issue in practive however.

# Binary Search Trees

Adding and deleting elements to an array is computationally expensive, particularly when the array needs to stay sorted. Binary search trees are similar to arrays in that the keys are in a sorted order and are easier to perform insertions and deletions to. They require more space than arrays however.

Insertion and deletion take $O(n)$ time if naively implemented. However, there are implementations of binary search trees which guarantee log(n) height.