{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Ensemble methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Simple way to create a better classifier\n",
    "\n",
    "aggregate the rpredictions of each classifier and predict the class that gets the most votes\n",
    "Hard votng classifier - majority rule\n",
    "\n",
    "provided we have enough learners that are diverse enough, an ensemble of low quality predictors can achive hagh accuracy\n",
    "\n",
    "they work the best when the predictors are independent and make uncorrelate errors\n",
    "\n",
    "we can achieve diverse classifiers by using different algorithms\n",
    "\n",
    "we can use predict proba  for soft voting which predicts the class with the highest average across all classifiers.\n",
    "\n",
    "often more efficient than hard voting because it puts more weight on confident votes.\n",
    "\n",
    "\n",
    "We can also get a diverse set of classifiers by using the same algorithm and using different subsets of the training set.\n",
    "\n",
    "Bagging - using the sampling performed with replacement\n",
    "pasting - when sampling is performed without replacement\n",
    "these allow training instances to be sampled several times across multiple predictors but only bagging allows for training instances to be sampled several times for the same predictor.\n",
    "\n",
    "aggregation function is usually the statistical mode for classificatio and the mean for regression.\n",
    "\n",
    "Each individual predictor has higher bias than if it were trained on the original training set, but aggregation usually reduces either bias or variance, if not both.\n",
    "\n",
    "\n",
    "baggin often ends up increasing bias and lower variance but bagging often ends us up with better models.\n",
    "\n",
    "\n",
    "with baggins some instnces  form the training set may be trained on repeatedly while some may be missed \n",
    "bagging classifier samples m instances with replacement `bootstrap = true` where m is the size of the training set\n",
    "\n",
    "samples about 63 percent of the training set\n",
    "\n",
    "this means we can use the inused instances on the test set\n",
    "we can evalate the ensemble by averaging the oob predictions of each predictor\n",
    "\n",
    "\n",
    "ensemble of decision trees with bagging\n",
    "introduces extra randomness when growing trees\n",
    "\n",
    "again higher bias and lower variance\n",
    "higher bias means higher diversity among predictors.\n",
    "\n",
    "When we are growing trees only a random subset of the features i considered for splitting\n",
    "can do random thresholds to make even more trees. Extra trees. much faster to train. because determining thresholds is time consuming.\n",
    "\n",
    "easy to measure importance of features with random forests\n",
    "\n",
    "feature importance for rf is how much a tree node uses that feaure to reduce impurity\n",
    "weighted avergae of nodes weight is number of training smaples associated with it.\n",
    "\n",
    "\n",
    "hypothesis boosting - using a lot of weak predictors to make a good predictor\n",
    "train sequaentiall each better thn the last\n",
    "\n",
    "adaptive boosting\n",
    "pay attention to where the previous model underfitted.increase weight of miscllassified trining instances, and so on\n",
    "\n",
    "similar to gradient descent\n",
    "\n",
    "cannot be parallelized. must be sequaentiall, so does not scale as well as bagging or pasting\n",
    "\n",
    "we can also fit data to resifual errors left behind\n",
    "\n",
    "shrinkage - scaling learning rate to be low so that we need more trees in an ensemble \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}