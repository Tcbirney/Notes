{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Linear Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This is the simplest model to predict a continuous numerical value. There are two approaches \n",
    "\n",
    "- The closed form solution: Normal Equation (aka Least Squares)\n",
    "- The Optimal Solution: Least Mean Squares using Gradient Descent\n",
    "\n",
    "Mathematical Notation:\n",
    "$\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 \\dots + \\theta_n x_n$\n",
    "\n",
    "Vith vectorized form\n",
    "\n",
    "$\\hat{y} = h_\\theta(x) = \\theta \\cdot x = \\theta ^ T x$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Performance Measures\n",
    "\n",
    "We use the mean squared error perormance measure.\n",
    "\n",
    "$$MSE(X, h_\\theta) = \\frac{1}{m} \\sum\\limits_{i=1}^m (\\theta ^T x^i-y^i)^2 \\textrm{ where m is the number of instances}\\\\$$\n",
    "\n",
    "There is also the mean absolute error performance measure\n",
    "\n",
    "$$MAE(X, h_\\theta) = \\frac{1}{m} \\sum\\limits_{i=1}^m |\\theta ^T x^i-y^i| \\textrm{ where m is the number of instances}\\\\$$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Linear Regression - Closed Form Solution\n",
    "\n",
    "$\\hat{\\theta} = (X^TX)^{-1}X^Ty$\n",
    "\n",
    "Here, $\\hat{\\theta}$ is the value of $\\theta$ that minimizes the cost function, and $y$ is the vector of the target values containing $y^{(1)}$ to $y^{(m)}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Nonlinear Regression - Polynomial Regression\n",
    "\n",
    "This recognizes non linear patters in datasets. To do this we add powers of each feature as new features, then we train a linear model on this extended set of features. This technique is called a __Polynomial regression__.\n",
    "\n",
    "When there are multiple features, polynomial regression allows us to find linear relations between feautes, unlike linear regression, because the PolynomialFeatures parameter defines the power of linear combinationsto create features for.\n",
    "\n",
    "High degree (around 300) polynomial regression will most likely fit the data better than plain linear regression."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Overfitting vs Underfitting\n",
    "\n",
    "We can overfit the data when the degree of the regression is too high, and we can also underfit data when the degree is too low.\n",
    "\n",
    "Overfitting: When the model performs well on training data, but generalizes poorly according to cross validation\n",
    "\n",
    "Underfitting: When the model performs poorly on training data and by cross validation metrics.\n",
    "\n",
    "Overfitting and Underfitting is a good way to see if the model is too simple or complex.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Learning Curves\n",
    "\n",
    "Learning curves are another way to tell if overfitting or underfitting occurs. Learning Curves are plots of the models performance with respect to the size of the training set. This way we can tell is the training set or the model size itself is the problem.\n",
    "\n",
    "Curves that show an underfitting model usually have error curves that reach close plateaus very early on, with high errors. __To resolve underfitting, you need to use better features or use a mode complex model__.\n",
    "\n",
    "\n",
    "Curves that show an overfitting model have the halmark sign of performance on the training data being significiantly better than on the validation data. On these, as we increase the overall size of the dataset, the lines would converge. __To resolve overfitting, we can either use more data, or use a simpler, lower degree model.__ We can use other techniques such as regularization to resolve overfitting.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Bias Variance Tradeoff\n",
    "\n",
    "Models generalizations error can be exptessed as the sum of 3 different errors.\n",
    "\n",
    "Bias: error due to wrong assumptions, such as assuming that the data is quadratic when it is linear. __High bias models are likely to underfit the data__\n",
    "\n",
    "Variance: error due to excessive sensitivity to small variations in the training data. __Models with many degrees of freedom (high polynomial models) have high variance and overfit data__\n",
    "\n",
    "Irreducible error: Error due to noisiness. Cleaning the data is the only solution."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Regularized Regression\n",
    "\n",
    "A method to avoid overfitting by constraining the model parameters.The fewer degrees of freedom, the harder it is to overfit. For linear models, the way to regularize the expression is to limit the weights applied to the features.\n",
    "\n",
    "We study 3 Regularized versions of Regressions\n",
    "- Lasso Regression\n",
    "- Ridge Regression\n",
    "- Elastic Net\n",
    "\n",
    "\n",
    "#### Ridge Regresssion\n",
    "\n",
    "\\begin{equation}\n",
    "\n",
    "J(\\theta) = MSE(\\theta) + \\alpha \\frac{1}{2}\\sum\\limits_{i=1}^n \\theta_i^2\\\\\n",
    "\n",
    "\\hat{\\theta} = (X^TX + \\alpha A)^{-1}X^Ty\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "#### Lasso Regresssion\n",
    "\n",
    "\\begin{equation}\n",
    "\n",
    "J(\\theta) = MSE(\\theta) + \\alpha \\frac{1}{2}\\sum\\limits_{i=1}^n |\\theta_i|\\\\\n",
    "\\end{equation}\n",
    "#### Elastic Net Regresssion\n",
    "\n",
    "\\begin{equation}\n",
    "\n",
    "J(\\theta) = MSE(\\theta) + \\alpha \\frac{1}{2}\\sum\\limits_{i=1}^n + \\alpha \\frac{1}{2}\\sum\\limits_{i=1}^n |\\theta_i|\\\\\n",
    "\\end{equation}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Gradient Descent\n",
    "\n",
    "A generic optimization algorithms capable of finding optimal solutions to a wide range of of problems. The general idea od gradient descent is to tweak paramters iteratively in order to minimize a cost function.\n",
    "\n",
    "Measures the local gradient of the error function, with respect to the paramter vector $\\theta$ and it goes in the direction of t descending gradient. Once the gradient is 0, you have reached a minimum.\n",
    "\n",
    "Ransom initialization is when you initialize the paramter vector with random values, then you improve it gradually.\n",
    "\n",
    "Learning Step: the amount that we are allowed to change the paramter vector by. If it is too small, it will take too long to reach the optimal solution, but if it is too large, the it will bounce around and also not reach an optimal solution.\n",
    "\n",
    "Gradient descent can get caught in plateaus and local minimums.\n",
    "\n",
    "\n",
    "### Convex Functions\n",
    "\n",
    "The MSE cost functions are convex, which means that there are no local minimima, just ont global minima.\n",
    "\n",
    "Since gradient descent takes the gradient of the mean square error, we have \n",
    "\n",
    "\\begin{equation}\n",
    "MSE(X, h_\\theta) = \\frac{1}{m} \\sum\\limits_{i=1}^m (\\theta ^T x^i-y^i)^2\\\\\n",
    "\n",
    "\\frac{d}{d\\theta_i}MSE(\\theta) = \\frac{2}{m} \\sum\\limits_{i=1}^m (\\theta ^T x^i-y^i)x_j^i\\\\\n",
    "\n",
    "\\end{equation}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Stochastic Gradient Descent\n",
    "The main problem with batch gradient descent is that it must use the whole training set to calculate the gradient at each step.\n",
    "\n",
    "The opposite is the Stochastic Gradient Descent which picks a random instance at the training set at every step and computes the gradient between these two points.\n",
    "\n",
    "### Minibatch Stochastic Gradient Descent\n",
    "Halfway between Gradient Descent and Stochastic Gradient Descent in that it computes the gradient on a random subset of data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Early Stopping\n",
    "\n",
    "Early stopping is a way to regularize iterative learning algorithms such as Gradient Descent. We stop as soon as our validation error reaches A minimum."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Used to estimate tbe probablility that an instance belongs to a class. If the eastimated probablility is greater than 0.5, then the model predicts that the instance elongs to the pisitive class. And otherwise it predicts that it belongs to the negative class.\n",
    "\n",
    "This maes linear regression a binary classifier.\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{p} = h_\\theta(x) = \\sigma(x^T\\theta) \\\\\n",
    "\\sigma(t) = \\frac{1}{1 + e^{-1}}\\\\\n",
    "\\end{equation}\n",
    "\n",
    "The predicted class $\\hat{y}$ is 1 if $\\hat{p} \\ge 0.5$ and 0 otherwise.\n",
    "\n",
    "Or 1 if $x^T\\theta$ is positive, and 0 otherwise."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}