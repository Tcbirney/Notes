{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Discrete Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Introduction to Discrete Feasible Planning\n",
    "\n",
    "Our planning model will be defined by our state space models. Each distinct situation for the world is a state, denoted with $x$, and the set of all possible states is $X$. In discrete planning, $X$ must be countable, and in almost all cases should be finite. We should be csarefull when defining our state space so that only relevant information is included and we are not wasting storage/computational space.\n",
    "\n",
    "The world may be transformed through the application of actions that are hosen by the planner. Each action $u$, when applied from the current sttate, produces a new state $x'$ as specified by a state transition function $f$. In other words\n",
    "\n",
    "$$x' = f(x, u)$$\n",
    "\n",
    "Let $U(x)$ denote the action space of the for each state $x$, which represents the set of all actions that could be applied from $x$. \n",
    "\n",
    "We can also notate the intiial state and goal state sets as $x_I$ and $X_G \\in X$\n",
    "\n",
    "Pretty similar to finiate state machines from undergrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Searching for Feasible Plans\n",
    "\n",
    "This section will mostly cover graph search algorithms, with the understanding that the state transition graph will be revealed incrementally through the application of actions, instead of being fully specified in advance. We will be reviewing graph search algorithms from a planning perspective, and an important qualification for these algorithms is that they must be systematic. \n",
    "\n",
    "If a graph is finite, then the algorithm will reach every state, which will allow the planner to determine whether there is a solution in finite time. In systematic algorithms we should keep track of the previously visited states or else we may loop over (possibly infinitely) states we have already visited.\n",
    "\n",
    "If the graph is infinite, then we may loosen the qualifications to make an algoithm systematic. If a solution exists then we wuld still report it in finite time, but if one does not exist, then it is acceptable for the algorithm to search forever. This still qualifies an algorithm as systematic, because in the limit as time continues then even in the infinite graph space, all states will eventually be reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 General Forward Search\n",
    "\n",
    "\n",
    "In general forward search, we will have 3 general kinds of states.\n",
    "\n",
    "1. __Unvisited:__ These states have not been visited yet, and initially this will include every state except for $x_I$\n",
    "\n",
    "2. __Dead:__ These states have been visited and every possible next state after this state has also been visited. We ccan remove this branch of choices from all possible options which may contribute to finding a solution.\n",
    "\n",
    "3. __Alive:__ These are states which have been visited and still may contain unvisited next states. These states are alie because they still may lead to us finding a solution.\n",
    "\n",
    "\n",
    "The set of all states are stored in a priority queue $Q$, for which a priority funstion must be specified. The only difference among this group of search algorithms is the function sued to sort $Q$. We will assume that $Q$ is a common FIFO queue for now. Initially $Q$ only contains the initial state $x_I$. A while loop will execute, iterating over all states, and will end when either the solution is found, or we run out of states (when $Q$ is empty), in which case we return a fail state. Unless the graph is infinite, in which case the search algorithm will run forever untill it finds a solution.\n",
    "\n",
    "In each iteration of the while loop, the highest ranked state $x$ of $Q$ is removed. If $x \\in X_g$ then we return with a success and terminate the loop, otherwise we apply every possible action $u$ such that $u \\in U(x)$ using the state transition function $f$. For each next state $x' = f(x, u)$ we must determine if $x'$ is being visited for the first time, and if so then it will be inserted into $Q$, otherwise we nned to do nothing because the state is eaither dead or already in $Q$. \n",
    "\n",
    "_Note that this implementation does not determine a plan, but only if there is a solution. This can be quickly implemented by attaching a parent state attribute to each state. This means we can just return the final goal state and recursiveley determine a path by travelling up the chain of parent nodes and pushing them on to a stack._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particular Search Implementations of Forqard Searches include\n",
    "\n",
    "Breadth First Search\n",
    "- append generated nodes to an open nodes queue. The way states are searched lyer by layer\n",
    "\n",
    "Deapth First Search\n",
    "- push generated nodes onto a stack. This way follow search branches untill we find a dead end before we explore more\n",
    "\n",
    "Dijkstras Search\n",
    "- Each state has an assciated cost to come from the start node whch s intilly specfid as infinity to declare them as unvisited. Generated nodes are pushed on to a priority queue which is a min heap sorted by the nodes cost to come. If node n1 generates an alive node n2, then update the c2c of n2 and make n1 the parent of n2. This algorithm guarantees the shortest path\n",
    "\n",
    "A* Search\n",
    "- And extension of dijkstras algorithm which tries to reduce the number of states explored by including a cost to go heuristic function. This measure estimates the istance between any node and the goal, but always is an optimal under estimate of the distance. This pattern often switches back and forth between paths as their path costs begin to outweigh each other\n",
    "\n",
    "\n",
    "Best First Search\n",
    "- This is another name for greedy search. Each choice at each node has an associated cost, be it the immediate edge cost of an estimated cost to go. Does not guarantee optimal solutions, but often explores fewer nodes and results in quicker running times.\n",
    "\n",
    "Iterative Deepening\n",
    "- Usefull for when our search tree has a large branching factor. Often occurs when there are many actions per state and only a few states are revisited. Main Idea is that we use depth first search and find all nodes between depth i and depth i + n. If no solution is found increase the depth limit. Has far better worst case scnario performance than breadth first search and space requirements are reduced. We can merge the ideas of A* and iterative deepening to create an IDA* search which includes a heuristic function as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Optimal Planning"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
